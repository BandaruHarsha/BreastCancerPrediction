# -*- coding: utf-8 -*-
"""Breast Cancer Prediction .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10kqoCsphU4nCtEK67THnXN7kEg1-73Wm
"""

#import

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#load data

from google.colab import files
uploaded = files.upload()
df = pd.read_csv('data.csv')
df.head(7)

#count dataset
df.shape

df.isna().sum()

df = df.dropna(axis=1)

df.shape

df['diagnosis'].value_counts()

#datatypes
df.dtypes

#Encode Values
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)
df.iloc[:,1]

#pair plot
sns.pairplot(df.iloc[:,1:5], hue='diagnosis')

df.head(5)

#correlation 
df.iloc[:,1:12].corr()

#visualize correlation
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:12].corr(), annot=True)

#split data cells

X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values

#split data cells into 75% and 25%

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

#function for model

def models(X_train, Y_train):

  #logictic regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state = 0)
  log.fit(X_train,Y_train)

  #decison tree
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
  tree.fit (X_train, Y_train)

  #randon forest classifier

  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  forest.fit (X_train, Y_train)

  #models accuracy on the training data

  print('[0] Logistic Regression training Accuracy :', log.score(X_train, Y_train)) 
  print('[1] Decision Treee Classifier training Accuracy :', tree.score(X_train, Y_train)) 
  print('[2] Random Forest Classifier training Accuracy :', forest.score(X_train, Y_train)) 

  return log, tree, forest

#getting models

model = models(X_train, Y_train)

#testing model accuracy on test data

from sklearn.metrics import confusion_matrix

for i in range (len(model)):
  print('Model ', i)
  cm = confusion_matrix(Y_test, model[i].predict(X_test))

  TP = cm [0][0]
  TN = cm [0][1]
  FN = cm [1][0]
  FP = cm [1][1]

  print(cm)
  print('Testing Accuracy = ', (TP+TN)/(TP+TN+FN+FP) )
  print()

#anotherway of testing

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

for i in range (len(model)):
  print('Model ', i)
  print(classification_report(Y_test, model[0].predict(X_test)))
  print(accuracy_score(Y_test, model[0].predict(X_test)))
  print()

#prediction of Random Forest Classifier model 

pred = model[2].predict(X_test)
print(pred)
print()
print(Y_test)

